{"cells":[{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:01:42.343517Z","iopub.status.busy":"2023-10-08T06:01:42.342989Z","iopub.status.idle":"2023-10-08T06:27:50.140760Z","shell.execute_reply":"2023-10-08T06:27:50.139873Z","shell.execute_reply.started":"2023-10-08T06:01:42.343447Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/5, Train Loss: 0.3379\n","Epoch 2/5, Train Loss: 0.1293\n","Epoch 3/5, Train Loss: 0.0800\n","Epoch 4/5, Train Loss: 0.0250\n","Epoch 5/5, Train Loss: 0.0838\n","Validation Accuracy: 0.9150\n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.93      0.91        96\n","           1       0.93      0.90      0.92       104\n","\n","    accuracy                           0.92       200\n","   macro avg       0.91      0.92      0.91       200\n","weighted avg       0.92      0.92      0.92       200\n","\n","Predicted Sentiment: Positive\n"]}],"source":["import pandas as pd\n","import torch\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# Load your dataset into a DataFrame (replace 'your_dataset.csv' with your actual dataset file)\n","df = pd.read_csv('Restaurant_Reviews.tsv', delimiter='\\t')\n","\n","# Split the dataset into train and validation sets (80% train, 20% validation)\n","train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n","\n","# Initialize the BERT tokenizer and model\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n","\n","# Define optimizer and learning rate scheduler\n","optimizer = AdamW(model.parameters(), lr=2e-5, no_deprecation_warning=True)\n","num_epochs = 5\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0\n","\n","    for i, row in train_df.iterrows():\n","        review = row['Review']\n","        label = row['Liked']\n","\n","        encoding = tokenizer(review, truncation=True, padding=True, return_tensors='pt')\n","        input_ids = encoding['input_ids']\n","        attention_mask = encoding['attention_mask']\n","\n","        optimizer.zero_grad()\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=torch.tensor([label]))\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","\n","    average_loss = total_loss / len(train_df)\n","    print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {average_loss:.4f}')\n","\n","# Evaluate the model on the validation set\n","model.eval()\n","val_labels = []\n","val_predictions = []\n","\n","for i, row in val_df.iterrows():\n","    review = row['Review']\n","    label = row['Liked']\n","\n","    encoding = tokenizer(review, truncation=True, padding=True, return_tensors='pt')\n","    input_ids = encoding['input_ids']\n","    attention_mask = encoding['attention_mask']\n","\n","    outputs = model(input_ids, attention_mask=attention_mask)\n","    logits = outputs.logits\n","    predictions = torch.argmax(logits, dim=1)\n","\n","    val_labels.append(label)\n","    val_predictions.append(predictions.item())\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(val_labels, val_predictions)\n","classification_report_str = classification_report(val_labels, val_predictions)\n","\n","print(f'Validation Accuracy: {accuracy:.4f}')\n","print(classification_report_str)\n","\n","# Define a function to predict sentiment\n","def predict_sentiment(input_text, model, tokenizer):\n","    # Tokenize the input text\n","    encoding = tokenizer(input_text, truncation=True, padding=True, return_tensors='pt')\n","    input_ids = encoding['input_ids']\n","    attention_mask = encoding['attention_mask']\n","\n","    # Pass the input through the model\n","    model.eval()\n","    with torch.no_grad():\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","    \n","    # Get the predicted class (0 for negative, 1 for positive)\n","    logits = outputs.logits\n","    predicted_class = torch.argmax(logits, dim=1).item()\n","\n","    # Determine the sentiment based on the predicted class\n","    if predicted_class == 0:\n","        return \"Negative\"\n","    else:\n","        return \"Positive\"\n","\n","# Example usage:\n","new_input_text = \"I really enjoyed the food at that restaurant.\"\n","sentiment = predict_sentiment(new_input_text, model, tokenizer)\n","print(f\"Predicted Sentiment: {sentiment}\")"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:28:34.300049Z","iopub.status.busy":"2023-10-08T06:28:34.299678Z","iopub.status.idle":"2023-10-08T06:28:34.365335Z","shell.execute_reply":"2023-10-08T06:28:34.364272Z","shell.execute_reply.started":"2023-10-08T06:28:34.300011Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Sentiment: Negative\n"]}],"source":["\n","# Example usage:\n","new_input_text = \"Worst restaurant ever\"\n","sentiment = predict_sentiment(new_input_text, model, tokenizer)\n","print(f\"Predicted Sentiment: {sentiment}\")"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:28:57.318623Z","iopub.status.busy":"2023-10-08T06:28:57.318244Z","iopub.status.idle":"2023-10-08T06:28:57.388578Z","shell.execute_reply":"2023-10-08T06:28:57.387326Z","shell.execute_reply.started":"2023-10-08T06:28:57.318594Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Sentiment: Positive\n"]}],"source":["# Example usage:\n","new_input_text = \"Parking is very congested\"\n","sentiment = predict_sentiment(new_input_text, model, tokenizer)\n","print(f\"Predicted Sentiment: {sentiment}\")"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:33:32.067331Z","iopub.status.busy":"2023-10-08T06:33:32.066853Z","iopub.status.idle":"2023-10-08T06:33:32.166455Z","shell.execute_reply":"2023-10-08T06:33:32.165437Z","shell.execute_reply.started":"2023-10-08T06:33:32.067294Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Sentiment: Negative\n"]}],"source":["# Example usage:\n","new_input_text = \"no parking place. We should park on the road itself\"\n","sentiment = predict_sentiment(new_input_text, model, tokenizer)\n","print(f\"Predicted Sentiment: {sentiment}\")"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:29:31.422619Z","iopub.status.busy":"2023-10-08T06:29:31.422225Z","iopub.status.idle":"2023-10-08T06:29:31.508626Z","shell.execute_reply":"2023-10-08T06:29:31.507547Z","shell.execute_reply.started":"2023-10-08T06:29:31.422591Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Sentiment: Positive\n"]}],"source":["# Example usage:\n","new_input_text = \"Food is avearge and ambience is very dirty\"\n","sentiment = predict_sentiment(new_input_text, model, tokenizer)\n","print(f\"Predicted Sentiment: {sentiment}\")"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:30:06.835477Z","iopub.status.busy":"2023-10-08T06:30:06.835062Z","iopub.status.idle":"2023-10-08T06:30:06.908853Z","shell.execute_reply":"2023-10-08T06:30:06.907574Z","shell.execute_reply.started":"2023-10-08T06:30:06.835446Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Sentiment: Negative\n"]}],"source":["# Example usage:\n","new_input_text = \"ambience is not good\"\n","sentiment = predict_sentiment(new_input_text, model, tokenizer)\n","print(f\"Predicted Sentiment: {sentiment}\")"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:30:27.155825Z","iopub.status.busy":"2023-10-08T06:30:27.155431Z","iopub.status.idle":"2023-10-08T06:30:27.233849Z","shell.execute_reply":"2023-10-08T06:30:27.232473Z","shell.execute_reply.started":"2023-10-08T06:30:27.155795Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Sentiment: Negative\n"]}],"source":["# Example usage:\n","new_input_text = \"ambience is very bad\"\n","sentiment = predict_sentiment(new_input_text, model, tokenizer)\n","print(f\"Predicted Sentiment: {sentiment}\")"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:30:43.171668Z","iopub.status.busy":"2023-10-08T06:30:43.171251Z","iopub.status.idle":"2023-10-08T06:30:43.241479Z","shell.execute_reply":"2023-10-08T06:30:43.240299Z","shell.execute_reply.started":"2023-10-08T06:30:43.171639Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Sentiment: Negative\n"]}],"source":["# Example usage:\n","new_input_text = \"space is very less to eat\"\n","sentiment = predict_sentiment(new_input_text, model, tokenizer)\n","print(f\"Predicted Sentiment: {sentiment}\")"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:31:16.540109Z","iopub.status.busy":"2023-10-08T06:31:16.539083Z","iopub.status.idle":"2023-10-08T06:31:16.610011Z","shell.execute_reply":"2023-10-08T06:31:16.608626Z","shell.execute_reply.started":"2023-10-08T06:31:16.540050Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Sentiment: Negative\n"]}],"source":["# Example usage:\n","new_input_text = \"food is not bad\"\n","sentiment = predict_sentiment(new_input_text, model, tokenizer)\n","print(f\"Predicted Sentiment: {sentiment}\")"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Sentiment: Positive\n"]}],"source":["new_input_text = \"food is ok\"\n","sentiment = predict_sentiment(new_input_text, model, tokenizer)\n","print(f\"Predicted Sentiment: {sentiment}\")"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Sentiment: Positive\n"]}],"source":["new_input_text = \"food is too salty\"\n","sentiment = predict_sentiment(new_input_text, model, tokenizer)\n","print(f\"Predicted Sentiment: {sentiment}\")"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Sentiment: Negative\n"]}],"source":["new_input_text = \"did not loved the food very much\"\n","sentiment = predict_sentiment(new_input_text, model, tokenizer)\n","print(f\"Predicted Sentiment: {sentiment}\")"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:31:33.067607Z","iopub.status.busy":"2023-10-08T06:31:33.066857Z","iopub.status.idle":"2023-10-08T06:31:33.131853Z","shell.execute_reply":"2023-10-08T06:31:33.130492Z","shell.execute_reply.started":"2023-10-08T06:31:33.067551Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Sentiment: Negative\n"]}],"source":["# Example usage:\n","new_input_text = \"not bad\"\n","sentiment = predict_sentiment(new_input_text, model, tokenizer)\n","print(f\"Predicted Sentiment: {sentiment}\")"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:31:58.898124Z","iopub.status.busy":"2023-10-08T06:31:58.897777Z","iopub.status.idle":"2023-10-08T06:31:58.960729Z","shell.execute_reply":"2023-10-08T06:31:58.959793Z","shell.execute_reply.started":"2023-10-08T06:31:58.898096Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Sentiment: Negative\n"]}],"source":["# Example usage:\n","new_input_text = \"disgusting\"\n","sentiment = predict_sentiment(new_input_text, model, tokenizer)\n","print(f\"Predicted Sentiment: {sentiment}\")"]},{"cell_type":"code","execution_count":27,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in c:\\users\\ruthu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.34.1)Note: you may need to restart the kernel to use updated packages.\n","\n","Requirement already satisfied: filelock in c:\\users\\ruthu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (3.12.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\ruthu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.17.3)\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\ruthu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (1.26.0)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\ruthu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ruthu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ruthu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2023.10.3)\n","Requirement already satisfied: requests in c:\\users\\ruthu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\ruthu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.14.1)\n","Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\ruthu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in c:\\users\\ruthu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in c:\\users\\ruthu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.9.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ruthu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n","Requirement already satisfied: colorama in c:\\users\\ruthu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ruthu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ruthu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ruthu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ruthu\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2023.7.22)\n"]}],"source":["pip install transformers"]},{"cell_type":"code","execution_count":28,"metadata":{"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/reviews/Restaurant_Reviews.tsv'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Ruthu\\OneDrive\\Desktop\\bert2[1].ipynb Cell 13\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ruthu/OneDrive/Desktop/bert2%5B1%5D.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ruthu/OneDrive/Desktop/bert2%5B1%5D.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m classification_report, accuracy_score\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Ruthu/OneDrive/Desktop/bert2%5B1%5D.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m/kaggle/input/reviews/Restaurant_Reviews.tsv\u001b[39;49m\u001b[39m'\u001b[39;49m, delimiter\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ruthu/OneDrive/Desktop/bert2%5B1%5D.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mcolumns)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/reviews/Restaurant_Reviews.tsv'"]}],"source":["import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","df = pd.read_csv('/kaggle/input/reviews/Restaurant_Reviews.tsv', delimiter='\\t')\n","print(df.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.columns\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df['Liked'].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df['Liked'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Split the dataset into train and validation sets (80% train, 20% validation)\n","train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n","\n","# Define a custom dataset class for BERT\n","class SentimentDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_length=128):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = str(self.texts[idx])\n","        label = int(self.labels[idx])\n","        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n","        return {\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'labels': torch.tensor(label, dtype=torch.long)\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Initialize the BERT tokenizer and dataset\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","train_dataset = SentimentDataset(train_df['Review'], train_df['Liked'], tokenizer)\n","val_dataset = SentimentDataset(val_df['Review'], val_df['Liked'], tokenizer)\n","train_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["val_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create data loaders\n","batch_size = 32\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","train_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for x,y in train_loader:\n","    optimizer.zerograd()\n","    \n","  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["optimizer = AdamW(model.parameters(), lr=2e-5, no_deprecation_warning=True)\n","num_epochs = 3"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0\n","\n","    for batch in train_loader:\n","        input_ids = batch['input_ids']\n","        attention_mask = batch['attention_mask']\n","        labels = batch['labels']\n","\n","        optimizer.zero_grad()\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","\n","    average_loss = total_loss / len(train_loader)\n","    print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {average_loss:.4f}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":4}
